{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d4db04a-a95e-4f23-991b-447d988ee158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspecto</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidade</th>\n",
       "      <th>Vento</th>\n",
       "      <th>Tenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sol</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sol</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nuvens</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chuva</td>\n",
       "      <td>Ameno</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chuva</td>\n",
       "      <td>Fresco</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chuva</td>\n",
       "      <td>Fresco</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nuvens</td>\n",
       "      <td>Fresco</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sol</td>\n",
       "      <td>Ameno</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sol</td>\n",
       "      <td>Fresco</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chuva</td>\n",
       "      <td>Ameno</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sol</td>\n",
       "      <td>Ameno</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nuvens</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nuvens</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chuva</td>\n",
       "      <td>Ameno</td>\n",
       "      <td>Elevada</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aspecto    Temp Humidade  Vento Tenis\n",
       "0      Sol  Quente  Elevada  Fraco   Não\n",
       "1      Sol  Quente  Elevada  Forte   Não\n",
       "2   Nuvens  Quente  Elevada  Fraco   Sim\n",
       "3    Chuva   Ameno  Elevada  Fraco   Sim\n",
       "4    Chuva  Fresco   Normal  Fraco   Sim\n",
       "5    Chuva  Fresco   Normal  Forte   Não\n",
       "6   Nuvens  Fresco   Normal  Fraco   Sim\n",
       "7      Sol   Ameno   Normal  Forte   Não\n",
       "8      Sol  Fresco   Normal  Fraco   Sim\n",
       "9    Chuva   Ameno  Elevada  Fraco   Sim\n",
       "10     Sol   Ameno   Normal  Forte   Sim\n",
       "11  Nuvens  Quente  Elevada  Fraco   Sim\n",
       "12  Nuvens  Quente   Normal  Forte   Sim\n",
       "13   Chuva   Ameno  Elevada  Forte   Não"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {\n",
    "    \"Aspecto\": [\"Sol\", \"Sol\", \"Nuvens\", \"Chuva\", \"Chuva\", \"Chuva\", \"Nuvens\", \"Sol\", \"Sol\", \"Chuva\", \"Sol\", \"Nuvens\", \"Nuvens\", \"Chuva\"],\n",
    "    \"Temp\": [\"Quente\", \"Quente\", \"Quente\", \"Ameno\", \"Fresco\", \"Fresco\", \"Fresco\", \"Ameno\", \"Fresco\", \"Ameno\", \"Ameno\", \"Quente\", \"Quente\", \"Ameno\"],\n",
    "    \"Humidade\": [\"Elevada\", \"Elevada\", \"Elevada\", \"Elevada\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Elevada\", \"Normal\", \"Elevada\", \"Normal\", \"Elevada\"],\n",
    "    \"Vento\": [\"Fraco\", \"Forte\", \"Fraco\", \"Fraco\", \"Fraco\", \"Forte\", \"Fraco\", \"Forte\", \"Fraco\", \"Fraco\", \"Forte\", \"Fraco\", \"Forte\", \"Forte\"],\n",
    "    \"Tenis\": [\"Não\", \"Não\", \"Sim\", \"Sim\", \"Sim\", \"Não\", \"Sim\", \"Não\", \"Sim\", \"Sim\", \"Sim\", \"Sim\", \"Sim\", \"Não\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2975d91-cdab-4b27-aba9-fa2715ca50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia(col):\n",
    "    counts = np.unique(col, return_counts=True)\n",
    "    N = float(col.shape[0])\n",
    "    ent = 0.0\n",
    "    for ix in counts[1]:\n",
    "        p = ix / N\n",
    "        ent += -1.0 * p * np.log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94969268-6754-48c8-8cc0-9f6415c11027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def information_gain(df, attr, target):\n",
    "    total = entropia(df[target])\n",
    "    valores = np.unique(df[attr])\n",
    "    acc = 0\n",
    "    for v in valores:\n",
    "        subset = df[df[attr] == v][target]\n",
    "        x = len(subset) / len(df)\n",
    "        acc += x * entropia(subset)\n",
    "    return total - acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a5efa-86d2-426b-b882-e3b5d16c0f3a",
   "metadata": {},
   "source": [
    "### Explicação da Função `information_gain`\n",
    "\n",
    "A função `information_gain(df, attr, target)` calcula o ganho de informação ao dividir os dados do DataFrame `df` pelo atributo `attr` para prever o atributo alvo `target`. Veja como ela funciona passo a passo:\n",
    "\n",
    "- **`total`**:  \n",
    "  Calcula a entropia do atributo alvo (`target`).  \n",
    "  Exemplo: se `target` for `\"Tenis\"`, estamos medindo a desordem (incerteza) na coluna `'Tenis'`, ou seja, o quão misturado está o \"Sim\"/\"Não\".\n",
    "\n",
    "- **`valores`**:  \n",
    "  Guarda os valores únicos do atributo escolhido (`attr`).  \n",
    "  Exemplo: se o atributo for `\"Aspecto\"`, `valores` será `[\"Sol\", \"Nuvens\", \"Chuva\"]`.\n",
    "\n",
    "- **Laço `for v in valores`:**  \n",
    "  Para cada valor possível do atributo, por exemplo, `v = \"Sol\"`, `v = \"Nuvens\"` ou `v = \"Chuva\"`:\n",
    "    - **`subset`**:  \n",
    "      Filtra o DataFrame, pegando só as linhas onde o atributo (`attr`) é igual a `v`.  \n",
    "      Depois, seleciona apenas a coluna do target (`Tenis`).\n",
    "    - **`x = len(subset) / len(df)`**:  \n",
    "      Calcula a proporção de linhas do DataFrame que têm aquele valor do atributo.\n",
    "    - **`acc += x * entropia(subset)`**:  \n",
    "      Soma (acumula) a entropia do subset, multiplicada pela proporção daquele valor no DataFrame.\n",
    "\n",
    "- **`return total - acc`**:  \n",
    "  O ganho de informação é a diferença entre a entropia total e a soma das entropias ponderadas dos subconjuntos.  \n",
    "  Isso mostra quanto saber o atributo (`attr`) reduz a incerteza sobre o target (`Tenis`).\n",
    "\n",
    "  Se quisermos calcular o ganho de informação ao dividir pelo atributo `\"Aspecto\"` para prever `\"Tenis\"`, a função irá:\n",
    "\n",
    "1. Calcular a entropia de `\"Tenis\"` para todas as linhas do DataFrame.\n",
    "2. Para cada valor de `\"Aspecto\"` (`\"Sol\"`, `\"Nuvens\"`, `\"Chuva\"`), calcular a entropia de `\"Tenis\"` apenas nas linhas daquele aspecto e ponderar pelo número de ocorrências desse aspecto.\n",
    "3. Retornar a diferença entre a entropia total e essa soma ponderada.\n",
    "\n",
    "Assim, descobrimos **quanto saber o \"Aspecto\" do tempo ajuda a prever se alguém vai jogar tênis ou não**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a0aa351-68bb-4be9-a1a2-7d82c2f0f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeCategorical:\n",
    "    def __init__(self, depth=0, max_depth=3):\n",
    "        self.children = {}\n",
    "        self.attr = None\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.target = None\n",
    "\n",
    "    def train(self, df, features, target):\n",
    "        if len(np.unique(df[target])) == 1 or len(features) == 0 or self.depth >= self.max_depth:\n",
    "            self.target = df[target].mode()[0]\n",
    "            return\n",
    "\n",
    "        gains = [information_gain(df, attr, target) for attr in features]\n",
    "        best_attr = features[np.argmax(gains)]\n",
    "        self.attr = best_attr\n",
    "        self.children = {}\n",
    "\n",
    "        for v in np.unique(df[best_attr]):\n",
    "            subset = df[df[best_attr] == v]\n",
    "            if subset.empty:\n",
    "                self.children[v] = None\n",
    "            else:\n",
    "                child = DecisionTreeCategorical(depth=self.depth+1, max_depth=self.max_depth) #Aqui definimos Child como objeto\n",
    "                child.train(subset, [f for f in features if f != best_attr], target)\n",
    "                self.children[v] = child #Para o valor v do atributo, o filho correspondente é o objeto child.\n",
    "\n",
    "    def predict(self, row):\n",
    "        if self.attr is None or self.children == {}:\n",
    "            return self.target\n",
    "        val = row[self.attr]\n",
    "        if val in self.children and self.children[val] is not None:\n",
    "            return self.children[val].predict(row)\n",
    "        else:\n",
    "            return self.target  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2898c-15b1-4590-80bb-edf0e921c42c",
   "metadata": {},
   "source": [
    "## Explicação do código: Classe `DecisionTree`\n",
    "\n",
    "### 1. Inicialização da Árvore (`__init__`)\n",
    "\n",
    "Ao criar uma instância da árvore de decisão, o método `__init__` é chamado para inicializar seus atributos:\n",
    "\n",
    "- **`self.children = {}`**  \n",
    "  - Um dicionário vazio que irá armazenar os nós filhos da árvore.  \n",
    "  - Cada chave corresponde a um valor do atributo de decisão (por exemplo, \"Sol\", \"Chuva\", etc.), e cada valor é uma subárvore (outro objeto `DecisionTree`).\n",
    "\n",
    "- **`self.attr`**  \n",
    "  - Este atributo armazenará o nome do atributo escolhido para dividir os dados naquele nó específico da árvore.  \n",
    "  - Cada nó da árvore pode ter um `self.attr` diferente, dependendo do melhor atributo selecionado para o split naquele ponto.\n",
    "\n",
    "- **`self.max_depth` & `self.depth`**  \n",
    "  - `self.max_depth`: Define a profundidade máxima permitida para a árvore.  \n",
    "  - `self.depth`: Indica em que nível da árvore o nó atual está (a raiz começa em 0).\n",
    "\n",
    "- **`self.target`**  \n",
    "  - Este atributo será preenchido em nós folha com o valor mais comum (modo) da variável alvo (`target`) nos dados daquele nó.\n",
    "---\n",
    "## 2.Critérios de Parada na Construção da Árvore de Decisão\n",
    "\n",
    "Durante o treinamento da árvore de decisão (método `train`), avaliamos algumas condições para determinar se devemos parar a criação de novos nós e transformar o nó atual em uma **folha**. Os principais critérios de parada são:\n",
    "\n",
    "1. **Limite de Profundidade**  \n",
    "   - Checamos se `self.depth >= self.max_depth`, ou seja, se a árvore já atingiu o limite máximo de profundidade permitido.\n",
    "\n",
    "2. **Target Puro**  \n",
    "   - Verificamos se todos os valores do nosso alvo (`target`) são iguais, como por exemplo `[yes, yes, yes]`. Nesse caso, não faz sentido continuar dividindo, pois todos os exemplos possuem o mesmo rótulo.\n",
    "\n",
    "3. **Acabaram as Features**  \n",
    "   - Conferimos se ainda existem atributos (`features`) disponíveis para realizar divisões. Se a lista estiver vazia, não é possível continuar.\n",
    "\n",
    "\n",
    "\n",
    "Quando qualquer uma dessas condições for satisfeita, o nó atual se torna uma folha, e atribuimos a ele o valor **mais comum** do nosso target no subconjunto de dados analisado.  \n",
    "Por exemplo, se o target no nó é `[yes, yes, yes]`, o valor atribuído será `yes`.\n",
    "\n",
    "---\n",
    "## 3.Escolha da Melhor Feature para Divisão\n",
    "\n",
    "Na construção da árvore de decisão, seguimos os passos abaixo para selecionar o atributo que mais contribui para a separação dos dados:\n",
    "\n",
    "1. **Cálculo do Ganho de Informação**  \n",
    "   - Calculamos o ganho de informação para cada uma das features disponíveis e armazenamos esses valores em uma lista.\n",
    "\n",
    "2. **Identificação do Maior Ganho**  \n",
    "   - Usamos `np.argmax(gains)` para encontrar o índice do maior valor de ganho de informação na lista.\n",
    "\n",
    "3. **Seleção da Melhor Feature**  \n",
    "   - Selecionamos a feature correspondente a esse índice e armazenamos seu nome na variável `best_attr`.  \n",
    "   - Esta será a feature utilizada para dividir o nó atual da árvore.\n",
    "## 4. Como funciona a recursividade na construção dos filhos da Decision Tree?\n",
    "\n",
    "No método `train` da nossa árvore de decisão, após escolher o melhor atributo (`best_attr`) para dividir o nó atual, seguimos os seguintes passos para construir seus filhos:\n",
    "\n",
    "---\n",
    "\n",
    "1. **Loop sobre os valores únicos do atributo selecionado**  \n",
    "   Utilizamos um `for` para percorrer cada valor possível de `best_attr`.  \n",
    "   **Exemplo:**  \n",
    "   Se `best_attr` for `\"Aspecto\"` e os valores possíveis forem `[Sol, Nuvens, Chuva]`, o loop irá funcionar assim:\n",
    "   - Primeira iteração: `x = \"Sol\"`\n",
    "   - Segunda iteração: `x = \"Nuvens\"`\n",
    "   - Terceira iteração: `x = \"Chuva\"`\n",
    "\n",
    "2. **Filtragem do DataFrame para cada valor**  \n",
    "   Para cada valor `x`, criamos um subconjunto do DataFrame apenas com as linhas onde `best_attr` é igual a `x`.  \n",
    "   **Exemplo:**  \n",
    "   - Para `x = \"Sol\"`, `sub` será todas as linhas onde `\"Aspecto\" == \"Sol\"`.\n",
    "   - Para `x = \"Nuvens\"`, `sub` será todas as linhas onde `\"Aspecto\" == \"Nuvens\"`.\n",
    "   - Para `x = \"Chuva\"`, `sub` será todas as linhas onde `\"Aspecto\" == \"Chuva\"`.\n",
    "\n",
    "3. **Criação do nó filho (\"Child\")**  \n",
    "   Para cada subconjunto `sub`, instanciamos um novo objeto `DecisionTree`, que será o nó filho correspondente ao valor `x`.  \n",
    "   **Exemplo:**  \n",
    "   - O nó `\"Sol\"` será um filho do nó atual, responsável por processar apenas os exemplos com `\"Aspecto\" == \"Sol\"`.\n",
    "\n",
    "4. **Recursividade para treinar o filho**  \n",
    "   Chamamos `child.train(sub, list(filter(lambda f: f != best_attr, features)), target)`.  \n",
    "   O que acontece aqui?  \n",
    "   - Chamamos novamente a função `train`, agora para o filho.  \n",
    "   - O DataFrame de entrada (`sub`) contém apenas exemplos onde o atributo tem valor `x` (por exemplo, apenas `\"Sol\"`).\n",
    "   - A lista de features é atualizada retirando `best_attr`, pois já foi usada para a divisão.\n",
    "   - O processo se repete: o filho tentará encontrar o melhor atributo para dividir os dados do seu subconjunto.\n",
    "\n",
    "   **Exemplo prático:**  \n",
    "   Imagine que no nó atual, `best_attr` é `\"Aspecto\"` e estamos na iteração `x = \"Sol\"`.  \n",
    "   - O DataFrame `sub` contém apenas linhas com `\"Aspecto\" == \"Sol\"`.\n",
    "   - Criamos o nó filho `\"Sol\"`.\n",
    "   - Chamamos `train` para esse filho, que irá procurar agora o melhor atributo (exceto `\"Aspecto\"`, que já foi usado) para dividir ainda mais o subconjunto de dados\n",
    "### Resumindo\n",
    "\n",
    "A cada iteração, dividimos o DataFrame conforme os valores do melhor atributo, criamos um nó filho para cada valor, e chamamos recursivamente o método `train` para cada filho, processando apenas o subconjunto de dados correspondente.  \n",
    "Dessa forma, a árvore vai “crescendo” de cima para baixo, especializando cada nó conforme os dados vão sendo filtrados!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0120d-d76f-4bfb-a929-ea49ddbb46f6",
   "metadata": {},
   "source": [
    "## (Importante) Explicação da função `predict`\n",
    "\n",
    "A função `predict` é responsável por prever o valor alvo (classe) para uma nova entrada na árvore de decisão. Vamos entender seu funcionamento passo a passo:\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Entrada da função\n",
    "\n",
    "- O parâmetro de entrada é `row`, que representa **uma linha do DataFrame** (ou seja, um exemplo com todos os atributos preenchidos).\n",
    "- **Exemplo:**  \n",
    "  ```python\n",
    "  row = {\n",
    "      \"Aspecto\": \"Sol\",\n",
    "      \"Temp\": \"Quente\",\n",
    "      \"Humidade\": \"Elevada\",\n",
    "      \"Vento\": \"Fraco\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Verificação de nó folha\n",
    "\n",
    "- O código verifica:\n",
    "  ```python\n",
    "  if self.attr is None or self.children == {}:\n",
    "      return self.target\n",
    "  ```\n",
    "- Isso significa que **se o nó atual não tem mais atributo para dividir (`self.attr is None`) ou não tem filhos (`self.children == {}`), então é uma folha**.\n",
    "- Nesse caso, a função retorna o valor de `self.target`, que é o valor mais comum do target naquele nó.\n",
    "- **Exemplo:**  \n",
    "  Se o nó representa todas as situações com `\"Aspecto\" == \"Sol\"` e a maioria delas resulta em `\"Tenis\" == \"Não\"`, então `self.target = \"Não\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Definindo o valor do atributo de decisão\n",
    "\n",
    "- A linha:\n",
    "  ```python\n",
    "  val = row[self.attr]\n",
    "  ```\n",
    "- **Significa:**  \n",
    "  Pegue o valor do atributo que está sendo usado para dividir neste nó.\n",
    "- **Exemplo:**  \n",
    "  Se `self.attr == \"Aspecto\"` e `row[\"Aspecto\"] == \"Sol\"`, então `val = \"Sol\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4) Decidindo para qual filho ir\n",
    "\n",
    "- O código verifica:\n",
    "  ```python\n",
    "  if val in self.children and self.children[val] is not None:\n",
    "      return self.children[val].predict(row)\n",
    "  else:\n",
    "      return self.target\n",
    "  ```\n",
    "- **Ou seja:**\n",
    "  - Se existe um filho correspondente ao valor de `val` (por exemplo, \"Sol\") e esse filho não é nulo, chamamos recursivamente a função `predict` no filho.\n",
    "  - **Exemplo Prático:**  \n",
    "    - Se estamos em um nó que divide por `Aspecto`, e `row[\"Aspecto\"] == \"Sol\"`, então procuramos o filho `self.children[\"Sol\"]`.\n",
    "    - Se existir, chamamos `predict` nesse filho, passando a mesma linha.\n",
    "    - Se esse filho for uma folha (não tem mais atributos para dividir), ele retorna seu `self.target` (por exemplo, \"Sim\" ou \"Não\").\n",
    "\n",
    "- **Se não existir filho para esse valor**, retornamos o valor alvo mais comum do nó atual (`self.target`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Fluxo resumido com exemplo**\n",
    "\n",
    "1. **Começamos na raiz:**  \n",
    "   - `self.attr == \"Aspecto\"`\n",
    "   - `row[\"Aspecto\"] == \"Sol\"`\n",
    "   - Vamos para o filho `\"Sol\"`\n",
    "\n",
    "2. **Filho \"Sol\":**\n",
    "   - Suponha que não há mais atributos para dividir (folha)\n",
    "   - `self.target == \"Não\"`\n",
    "   - Retorna `\"Não\"` como predição\n",
    "\n",
    "---\n",
    "\n",
    "### **Resumo**\n",
    "\n",
    "- A cada chamada, a função verifica se é folha; se não for, escolhe o próximo nó filho de acordo com o valor do atributo de decisão.\n",
    "- O processo é recursivo e termina em uma folha, retornando a classe prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d74075af-8dbc-46f5-9c90-63392e8f0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\"Aspecto\", \"Temp\", \"Humidade\", \"Vento\"]\n",
    "target = \"Tenis\"\n",
    "tree = DecisionTreeCategorical(max_depth=3)\n",
    "tree.train(df, features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb390685-70e0-401e-89fa-6c58a594a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 1: Previsto=Não, Real=Não\n",
      "Exemplo 2: Previsto=Não, Real=Não\n",
      "Exemplo 3: Previsto=Sim, Real=Sim\n",
      "Exemplo 4: Previsto=Sim, Real=Sim\n",
      "Exemplo 5: Previsto=Sim, Real=Sim\n",
      "Exemplo 6: Previsto=Não, Real=Não\n",
      "Exemplo 7: Previsto=Sim, Real=Sim\n",
      "Exemplo 8: Previsto=Não, Real=Não\n",
      "Exemplo 9: Previsto=Sim, Real=Sim\n",
      "Exemplo 10: Previsto=Sim, Real=Sim\n",
      "Exemplo 11: Previsto=Não, Real=Sim\n",
      "Exemplo 12: Previsto=Sim, Real=Sim\n",
      "Exemplo 13: Previsto=Sim, Real=Sim\n",
      "Exemplo 14: Previsto=Não, Real=Não\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    test_row = df.iloc[i]\n",
    "    print(f\"Exemplo {i+1}: Previsto={tree.predict(test_row)}, Real={test_row[target]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
